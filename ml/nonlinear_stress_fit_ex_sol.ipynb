{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "463264de-6a14-405a-be0e-baf114e4d744",
   "metadata": {},
   "source": [
    "# Exercise - approximating a stress-strain relation with a neural network\n",
    "\n",
    "In this exercise, you will build a neural network to reconstruct the model parameters from given stress-strain curves. Let us assume that the stress-strain relation is well approximated [_Ramberg-Osgood_](https://en.wikipedia.org/wiki/Rambergâ€“Osgood_relationship) model, which represents a non-linear relation between the stress $\\sigma$  and the strain $\\epsilon$, namely\n",
    "$$ \\sigma = C \\epsilon^{1/n}.$$\n",
    "Here, $C$ and $n$ denote the material parameters, which should be identified based on given stress-strain curves. Specifically, for each stress-strain curve, the model should output a pair $(C,n)$: hence, we are dealing with a _multi-target regression_ problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7ff4e6-165b-4e66-a129-95ecf1d34ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from data.data_generator import StressStrainDataGenerator\n",
    "from torch import nn\n",
    "import torch\n",
    "from skorch import NeuralNetRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04971af-e821-4b04-8ecc-b0ce2c2aa5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliary functions\n",
    "def get_stress_from_model(eps, C, n):\n",
    "    return C*eps**(1.0/n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51a3d99-7fd4-44c0-8b44-deefce2158c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate dataset: each sample (row) consists of strains and stresses arranged sequentially \n",
    "# (first NUM_DATAPOINTS columns corresponds to strains, the rest to the associated stresses)\n",
    "NUM_DATAPOINTS = 101\n",
    "stressStrainDataGenerator = StressStrainDataGenerator(num_datapoints=NUM_DATAPOINTS) \n",
    "stressStrainDataGenerator.std_noise =  0.554\n",
    "X, y = stressStrainDataGenerator.generate_stress_strain_datasets(num_samples=2000,\n",
    "                                                                          C_range=[5,15],\n",
    "                                                                          n_range=[2,5],\n",
    "                                                                          shuffle=True,\n",
    "                                                                          add_noise=True,\n",
    "                                                                          eps_linear_distributed=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e795af-3a4a-4729-80a6-33a59622d6ea",
   "metadata": {},
   "source": [
    "1. Plot 6 stress-strain curves of the dataset using a scatter plot. Display a legend that relates the values of $C$ and $n$ to each curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d82aa40-ac5c-4709-9280-a4ec4189caaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_plotted_curves = 6\n",
    "for sample_index in range(0, num_plotted_curves):\n",
    "    strains = X[sample_index][0:NUM_DATAPOINTS]\n",
    "    stresses = X[sample_index][NUM_DATAPOINTS:]\n",
    "    label = '$C = {:.2f}$, $n = {:.2f}$'.format(*y[sample_index])\n",
    "    plt.plot(strains, stresses, 'o', label=label)\n",
    "plt.xlabel(\"strain [-]\")\n",
    "plt.ylabel(\"stress\")\n",
    "plt.legend(ncol=2);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7f80d5-ac51-4302-859a-b403a4bb5ea8",
   "metadata": {},
   "source": [
    "2. Split the dataset into training and test sets (0.8-0.2) using the _scikit-learn_ function [`train_test_split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html). Call the resulting arrays `X_train`, `X_test`, `y_train`, `y_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bfea2c-db9c-46ea-8a99-16f7bbde77e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3f94a4-6327-42db-a2de-06edc2ef6265",
   "metadata": {},
   "source": [
    "3. Create a _PyTorch_ neural network class that implements a multi-layer perceptron to predict the values of $C$ and $n$ given an array combining strains and stresses. Fix the number of hidden layers to 3 and define a parameter called `hidden_units` in the constructor of the class that allows to change the number of units for each hidden layer (for simplicity, assume that the number is the same for all hidden layers).\n",
    "\n",
    "**NOTE**: in the `forward` method of the class, process the input _x_ with the instruction `x = x.to(torch.float32)` before passing it to the hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec77031-d674-4a10-b778-c5882be57399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# these tensors must be used for the training of the neural network\n",
    "X_ = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_ = torch.tensor(y_train, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4c2c88-42fe-4c9d-a532-163d2f333c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, hidden_units=50):\n",
    "        super().__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(2*NUM_DATAPOINTS, hidden_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_units, hidden_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_units, hidden_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_units, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(torch.float32)\n",
    "        x = self.linear_relu_stack(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477f58ad-a3d9-4501-b976-090fa78d6b97",
   "metadata": {},
   "source": [
    "4. Create a _skorch_ `NeuralNetRegressor` object (see the docs [here](https://skorch.readthedocs.io/en/stable/regressor.html)) that wraps the Pytorch model. Set the learning rate equal to 0.01 and the batch size equal to 64. Disable train/validation split, set the parameter `verbose=0` (to avoid printing anything during the grid search runs, see point 6) and set the number of epochs equal to 20. Check that the optimizer is set to SGD and that the loss function is MSE. When calling the `NeuralNetRegressor` constructor, also pass the parameter `module__hidden_units=10` to set the default number of hidden units.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f19e183-6cb8-4ed6-bc29-e53de22bfa7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetRegressor(module=NeuralNetwork, lr=0.01, batch_size=64, verbose=0,\n",
    "                           max_epochs=20, train_split=None, module__hidden_units=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b3303c-cbeb-4b44-8f12-861f9403ee78",
   "metadata": {},
   "source": [
    "5. Create a _scikit-learn_ `Pipeline` object (see docs\n",
    "   [here](https://scikit-learn.org/1.5/modules/generated/sklearn.pipeline.Pipeline.html))\n",
    "   that appropriately standardizes the dataset and feeds it to the `NeuralNetRegressor`\n",
    "   object. Name the model object in the pipeline as `model`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52abdb1a-9e0e-49ae-ac5e-55231cd200d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('model', model),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0469a6f8-4844-407b-ab8c-fc8bd4cee182",
   "metadata": {},
   "source": [
    "6. Use the [`GridSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV) interface of _scikit-learn_ to carry out a grid search on the parameter called `model__module__hidden_units` (which is passed to the `model` in the pipeline that you just built). Use 3-fold cross-validation. Also check the _User Guide_ of _scikit-learn_ about the grid search. Print the number of hidden units that results in the best validation score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b630b38-9541-45ff-8d89-2f6900ca48b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'model__module__hidden_units': [10*(i+1) for i in range(10)],\n",
    "}\n",
    "gs = GridSearchCV(pipe, params, cv=3, verbose=3)\n",
    "gs.fit(X_, y_)\n",
    "\n",
    "print(gs.best_score_, gs.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf02c74-c726-40c4-86cc-13343e0f7e70",
   "metadata": {},
   "source": [
    "7. Plot the training loss vs number of epochs for the best model found in the grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145a8d30-a818-4c7f-986f-419777c66461",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = gs.best_estimator_['model'].history[:, 'train_loss']\n",
    "plt.plot([i for i in range(1,21)], train_loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4e1eeb-e339-463a-ae24-98bfc18de396",
   "metadata": {},
   "source": [
    "8. Using the best model obtained from the grid search, generate the predictions over the test set and evaluate the $R^2$ on this set. Plot the stresses and the strains corresponding to one sample of the test set along with the curve obtained using the function `get_stress_from_model` with the values of $C$ and $n$ estimated by the trained neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d0b466-cc6a-4267-b6fc-635fd3634020",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = gs.predict(X_test)\n",
    "gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979189d3-3650-4528-b327-8dbdb6678804",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_number = 1\n",
    "strains_stresses = X_test[sample_number]\n",
    "C, n = p[sample_number]\n",
    "print(p[sample_number])\n",
    "print(y_test[sample_number])\n",
    "strains = X_test[sample_number][:NUM_DATAPOINTS]\n",
    "stresses = X_test[sample_number][NUM_DATAPOINTS:]\n",
    "pred_stresses = get_stress_from_model(strains, C, n)\n",
    "plt.plot(strains, stresses, 'o')\n",
    "plt.plot(strains, pred_stresses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa47758-bfaf-4cd2-8be5-684214af649d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
