{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise - Regularized polynomial regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first part of this exercise, you will implement regularized linear regression to\n",
    "predict the amout of water flowing out of a dam as a function of the change of water\n",
    "level in a reservoir.\n",
    "\n",
    "The provided dataset consists of one feature (change in water level) and one label\n",
    "(amout of water flowing out of the dam) and it is divided into three parts corresponding\n",
    "to the training, validation and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the path if needed\n",
    "data = loadmat('data/poly_regression/ex5data1.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract train, test, validation data\n",
    "X, y = data['X'], data['y'][:, 0] # training set\n",
    "Xtest, ytest = data['Xtest'], data['ytest'][:, 0]\n",
    "Xval, yval = data['Xval'], data['yval'][:, 0]\n",
    "\n",
    "y = y.reshape(-1,1)\n",
    "yval = yval.reshape(-1,1)\n",
    "ytest = ytest.reshape(-1,1)\n",
    "\n",
    "# Number of samples\n",
    "N = y.size\n",
    "\n",
    "# Plot training data\n",
    "plt.plot(X, y, 'ro', ms=6, mec='k', mew=1)\n",
    "plt.xlabel('Change in water level (x)')\n",
    "plt.ylabel('Water flowing out of the dam (y)');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding column of ones\n",
    "X_ = np.hstack((np.ones((X.shape[0],1)), X))\n",
    "Xval_ = np.hstack((np.ones((Xval.shape[0],1)), Xval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliary function for dataset normalization\n",
    "def featureNormalize(X):\n",
    "    mu = np.mean(X, axis=0)\n",
    "    X_norm = X - mu\n",
    "\n",
    "    sigma = np.std(X_norm, axis=0, ddof=1)\n",
    "    X_norm /= sigma\n",
    "    return X_norm, mu, sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Implement the `RegularizedLinearRegression` class by extending the `LinearRegression`\n",
    "   class seen in the previous exercises. The cost function should include a L2\n",
    "   regularization term and the appropriate gradient of it should be computed for\n",
    "   gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegularizedLinearRegression:\n",
    "    def __init__(self, num_features=1):\n",
    "        pass\n",
    "\n",
    "    # Here lam is the regularization factor\n",
    "    def fit(self, X, y, learning_rate, epochs, lam=0.):\n",
    "        pass\n",
    "    \n",
    "    def loss(self, prediction, y, lam):\n",
    "        pass\n",
    "\n",
    "    def predict(self, X):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Train the model with zero regularization (standard linear regression) and plot the\n",
    "   best fit line along with the training data. (Dataset normalization is not needed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Compute the errors on the training and the validation datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding polynomial features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem with our linear model was that it was too simple for the data, and resulted in underfitting (high bias). In this part of the exercise, you will address this problem by adding more features. For polynomial regression, our hypothesis has the form:\n",
    "    $$\n",
    "    \\begin{align}\n",
    "    h_\\theta(x)  &= \\theta_0 + \\theta_1 \\times (\\text{waterLevel}) + \\theta_2 \\times\n",
    "    (\\text{waterLevel})^2 + \\cdots + \\theta_p \\times (\\text{waterLevel})^p \\\\   \n",
    "    & = \\theta_0 + \\theta_1 x_1 + \\theta_2 x_2 + \\cdots + \\theta_p x_p\n",
    "    \\end{align}\n",
    "    $$\n",
    "\n",
    "Notice that by defining $x_1 = (\\text{waterLevel})$, $x_2 = (\\text{waterLevel})^2$ ,\n",
    "$\\cdots$, $x_p = (\\text{waterLevel})^p$, we obtain a linear regression model where the\n",
    "features are the various powers of the original value (waterLevel).\n",
    "\n",
    "Now, you will add more features using the higher powers of the existing feature $x$ in\n",
    "the dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Complete the code in the function `polyFeatures` in the next cell. The function should map the original training set $X$\n",
    "of size $N \\times 1$ into its higher powers. Specifically, when a training set $X$ of size $N \\times 1$ is passed into the function, the function should return a $N \\times p$ matrix `X_poly`, where column 1 holds the original values of X, column 2 holds the values of $X^2$, column 3 holds the values of $X^3$, and so on. Note that you donâ€™t have to account for the zero-eth power in this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polyFeatures(X, p):\n",
    "    \"\"\"\n",
    "    Maps X (1D vector) into the p-th power.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array_like\n",
    "        A data vector of size m, where m is the number of examples.\n",
    "    \n",
    "    p : int\n",
    "        The polynomial power to map the features. \n",
    "    \n",
    "    Returns \n",
    "    -------\n",
    "    X_poly : array_like\n",
    "        A matrix of shape (m x p) where p is the polynomial \n",
    "        power and m is the number of examples. That is:\n",
    "    \n",
    "        X_poly[i, :] = [X[i], X[i]**2, X[i]**3 ...  X[i]**p]\n",
    "    \"\"\"\n",
    "    # X_poly = ...\n",
    "    return X_poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the polynomial features up to 8-th degree\n",
    "p = 8\n",
    "\n",
    "# Datasets standardization\n",
    "X_poly = polyFeatures(X, p)\n",
    "X_poly, mu_X, sigma_X = featureNormalize(X_poly)\n",
    "X_poly = np.concatenate([np.ones((N, 1)), X_poly], axis=1)\n",
    "ynorm, mu_y, sigma_y = featureNormalize(y)\n",
    "\n",
    "X_poly_test = polyFeatures(Xtest, p)\n",
    "X_poly_test -= mu_X\n",
    "X_poly_test /= sigma_X\n",
    "X_poly_test = np.concatenate([np.ones((ytest.size, 1)), X_poly_test], axis=1)\n",
    "ytest -= mu_y\n",
    "ytest /= sigma_y\n",
    "\n",
    "X_poly_val = polyFeatures(Xval, p)\n",
    "X_poly_val -= mu_X\n",
    "X_poly_val /= sigma_X\n",
    "X_poly_val = np.concatenate([np.ones((yval.size, 1)), X_poly_val], axis=1)\n",
    "yval -= mu_y\n",
    "yval /= sigma_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Train the model using the polynomial features. Choose 0.01 for the learning rate and\n",
    "   10000 for the epochs. Plot the history of the loss. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Execute the following cell to plot the training set and the fitted polynomial model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We plot a range slightly bigger than the min and max values to get\n",
    "# an idea of how the fit will vary outside the range of the data points\n",
    "x = np.arange(np.min(X) - 25, np.max(X) + 25, 0.05).reshape(-1, 1)\n",
    "\n",
    "# Map the X values\n",
    "x_poly = polyFeatures(x, p)\n",
    "x_poly -= mu_X\n",
    "x_poly /= sigma_X\n",
    "\n",
    "# Add ones\n",
    "x_poly = np.concatenate([np.ones((x.shape[0], 1)), x_poly], axis=1)\n",
    "\n",
    "# De-scale predictions\n",
    "y_pred = sigma_y*lr.predict(x_poly) + mu_y\n",
    "plt.plot(x, y_pred, '--', lw=2)\n",
    "\n",
    "plt.plot(X, y, 'ro', ms=6, mec='k', mew=1)\n",
    "\n",
    "plt.xlabel('Change in water level (x)')\n",
    "plt.ylabel('Water flowing out of the dam (y)');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Compute the MSE on the training and the validation datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Find the value of the regularization parameter in the interval $[0,10]$ that minimizes the\n",
    "   validation MSE. Plot the training and validation MSEs as a function of the learning rate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Use the optimal value of the regularization parameter found in the previous step to re-train the\n",
    "   model. Plot the model predictions and the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Evaluate the MSEs on the training, validation and test sets for the re-trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datasim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
